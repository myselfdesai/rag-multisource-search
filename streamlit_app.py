"""Streamlit UI for RAG Challenge application."""
import streamlit as st
import requests
import json
import os
import tempfile
from pathlib import Path
import time
from datetime import datetime
from io import BytesIO
import pandas as pd

API_URL = os.getenv("API_URL", "http://localhost:8000")
DEFAULT_NAMESPACE = os.getenv("DEFAULT_NAMESPACE", "prod")


def check_api_health():
    """Check if FastAPI server is running."""
    try:
        response = requests.get(f"{API_URL}/health", timeout=2)
        return response.status_code == 200
    except:
        return False


def validate_file_upload(file) -> tuple[bool, str]:
    """
    Validate uploaded file.
    
    Returns:
        Tuple of (is_valid, error_message)
    """
    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50 MB
    ALLOWED_EXTENSIONS = {'.pdf', '.docx', '.csv'}
    
    # Check file size
    file_size = file.size
    if file_size > MAX_FILE_SIZE:
        return False, f"File size ({file_size / 1024 / 1024:.1f} MB) exceeds maximum allowed size (50 MB)"
    
    # Check file extension
    file_ext = Path(file.name).suffix.lower()
    if file_ext not in ALLOWED_EXTENSIONS:
        return False, f"File type '{file_ext}' not supported. Allowed types: PDF, DOCX, CSV"
    
    # Basic validation passed
    return True, ""


def upload_document(file, namespace: str):
    """Upload and ingest a document via API."""
    # Validate file first
    is_valid, error_msg = validate_file_upload(file)
    if not is_valid:
        return {"success": False, "message": error_msg}
    
    with tempfile.TemporaryDirectory() as tmpdir:
        file_path = os.path.join(tmpdir, file.name)
        with open(file_path, "wb") as f:
            f.write(file.getbuffer())
        
        try:
            from ingest.ingest import ingest_document
            from storage.pinecone_store import PineconeStore
            
            store = PineconeStore(namespace=namespace)
            num_chunks = ingest_document(file_path, namespace, store, reingest=False)
            return {"success": True, "chunks": num_chunks, "message": f"Successfully ingested {num_chunks} chunks"}
        except Exception as e:
            return {"success": False, "message": f"Ingestion error: {str(e)}"}


def query_api(question: str, namespace: str, top_k: int = 20, source_type: str = None):
    """Query the RAG API."""
    payload = {
        "question": question,
        "namespace": namespace,
        "top_k": top_k,
        "source_type": source_type if source_type else None,
        "retrieval_only": False
    }
    
    try:
        response = requests.post(f"{API_URL}/query", json=payload, timeout=60)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        return {"error": str(e)}




def main():
    st.set_page_config(
        page_title="RAG Challenge - Document Q&A",
        page_icon=None,
        layout="wide"
    )
    
    st.title("RAG Challenge - Document Q&A System")
    st.markdown("Retrieval-Augmented Generation for document question answering")
    
    if not check_api_health():
        st.error(f"FastAPI server is not running at {API_URL}")
        st.info("Please start the server with: `pipenv run python -m app.main`")
        st.stop()
    else:
        st.success("API server is running")
    
    tab1, tab2, tab3, tab4 = st.tabs([" Query Documents", "üì§ Upload Documents", "üìä Evaluation Results", "‚öôÔ∏è Status"])
    
    with tab1:
        st.header("Query Documents")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            question = st.text_area(
                "Enter your question:",
                height=100,
                placeholder="e.g., What is the main topic of this document?",
                key="question_input"
            )
        
        with col2:
            namespace = "prod"  # Fixed to prod namespace
            top_k = st.slider("Top K results", min_value=5, max_value=50, value=20, step=5)
            source_type = st.selectbox("Filter by source type", [None, "pdf", "docx", "csv"], format_func=lambda x: "All" if x is None else x.upper())
        
        if st.button("Search", type="primary", use_container_width=True):
            question_stripped = question.strip()
            
            # Client-side validation
            if not question_stripped:
                st.warning("Please enter a question")
            elif len(question_stripped) < 3:
                st.warning("Question must be at least 3 characters long")
            elif len(question_stripped) > 2000:
                st.warning("Question is too long (maximum 2000 characters)")
            else:
                with st.spinner("Searching documents and generating answer..."):
                    result = query_api(
                        question=question_stripped,
                        namespace=namespace,
                        top_k=top_k,
                        source_type=source_type
                    )
                
                if "error" in result:
                    st.error(f"Error: {result['error']}")
                else:
                    st.success("Query completed!")
                    
                    st.subheader("Answer")
                    st.markdown(result.get("answer", "No answer generated"))
                    
                    sources = result.get("sources", [])
                    if sources:
                        st.subheader(f"Sources ({len(sources)})")
                        
                        for i, source in enumerate(sources, 1):
                            with st.expander(f"Source {i}: {source.get('source_name', 'Unknown')} - {source.get('locator', 'N/A')}"):
                                st.markdown(f"**Document ID:** `{source.get('doc_id', 'N/A')}`")
                                st.markdown(f"**Location:** {source.get('locator', 'N/A')}")
                                if source.get('similarity_score'):
                                    st.markdown(f"**Similarity Score:** {source.get('similarity_score', 0):.4f}")
                                st.markdown("**Snippet:**")
                                st.code(source.get('snippet', ''), language=None)
                    
                    meta = result.get("meta", {})
                    with st.expander("Query Metadata"):
                        st.json(meta)
    
    with tab2:
        st.header("Upload Documents")
        st.markdown("Upload PDF, DOCX, or CSV files to ingest into the vector store")
        
        namespace = "prod"  # Fixed to prod namespace
        
        uploaded_file = st.file_uploader(
            "Choose a file",
            type=["pdf", "docx", "csv"],
            help="Supported formats: PDF, DOCX, CSV"
        )
        
        if uploaded_file is not None:
            file_details = {
                "Filename": uploaded_file.name,
                "FileType": uploaded_file.type,
                "FileSize": f"{uploaded_file.size / 1024:.2f} KB"
            }
            st.json(file_details)
            
            if st.button("Upload & Ingest", type="primary", use_container_width=True):
                with st.spinner(f"Ingesting {uploaded_file.name}..."):
                    result = upload_document(uploaded_file, namespace)
                
                if result.get("success"):
                    st.success(f"{result.get('message', 'Document ingested successfully')}")
                    if "chunks" in result:
                        st.info(f"Created {result['chunks']} chunks from the document")
                else:
                    st.error(f"Error: {result.get('message', 'Unknown error')}")
    
    with tab3:
        st.header("üìä Evaluation Results")
        st.markdown("RAGAS evaluation metrics for assessing RAG system performance")
        
        results_file = Path("eval/results/latest_results.json")
        
        if results_file.exists():
            with open(results_file, 'r', encoding='utf-8') as f:
                eval_results = json.load(f)
            
            # Display timestamp
            st.info(f"üïí Last evaluated: {eval_results.get('timestamp', 'Unknown')}")
            
            # Overall Metrics Section
            st.subheader("üéØ Overall Performance")
            overall_metrics = eval_results.get("overall_metrics", {})
            
            if overall_metrics:
                # Create metrics display in columns
                cols = st.columns(3)
                metric_order = [
                    ("faithfulness", "Faithfulness", "üéØ"),
                    ("answer_relevancy", "Answer Relevancy", "üéØ"),
                    ("context_precision", "Context Precision", "üîç"),
                    ("context_recall", "Context Recall", "üìã"),
                    ("answer_correctness", "Answer Correctness", "‚úì"),
                    ("answer_similarity", "Answer Similarity", "‚âà")
                ]
                
                for idx, (key, label, emoji) in enumerate(metric_order):
                    if key in overall_metrics:
                        col_idx = idx % 3
                        with cols[col_idx]:
                            score = overall_metrics[key]
                            st.metric(
                                label=f"{emoji} {label}",
                                value=f"{score:.3f}"
                            )
                
                # Show as table too
                st.divider()
                metrics_df = pd.DataFrame([overall_metrics])
                # Only format numeric columns
                st.dataframe(metrics_df.style.format(lambda x: f"{x:.4f}" if isinstance(x, (int, float)) else x), use_container_width=True)
            
            # Per-Query Results
            st.divider()
            st.subheader("üìù Per-Query Details")
            
            queries = eval_results.get("queries", [])
            st.write(f"Total queries evaluated: **{len(queries)}**")
            
            for idx, query_result in enumerate(queries, 1):
                with st.expander(f"Query {idx}: {query_result['question'][:80]}..."):
                    # Question and Answer
                    st.markdown("**Question:**")
                    st.info(query_result['question'])
                    
                    st.markdown("**Generated Answer:**")
                    st.success(query_result['answer'])
                    
                    st.markdown("**Ground Truth:**")
                    st.warning(query_result.get('ground_truth', 'N/A'))
                    
                    # Metrics for this query
                    if 'metrics' in query_result:
                        st.markdown("**Metrics:**")
                        metrics_df = pd.DataFrame([query_result['metrics']])
                        # Only format numeric columns
                        st.dataframe(metrics_df.style.format(lambda x: f"{x:.4f}" if isinstance(x, (int, float)) else x), use_container_width=True)
                    
                    # Retrieved Contexts
                    if 'contexts' in query_result:
                        with st.expander(f"üìö View Retrieved Contexts ({len(query_result['contexts'])} chunks)"):
                            for ctx_idx, context in enumerate(query_result['contexts'], 1):
                                st.markdown(f"**Context {ctx_idx}:**")
                                st.code(context[:300] + "..." if len(context) > 300 else context)
                    
                    # Sources
                    if 'sources' in query_result:
                        st.markdown(f"**Sources:** {len(query_result['sources'])} documents")
        
        else:
            st.warning("‚ö†Ô∏è No evaluation results found")
    
    with tab4:
        st.header("System Status")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("API Health")
            if check_api_health():
                st.success("API server is healthy")
                try:
                    response = requests.get(f"{API_URL}/health", timeout=2)
                    health_data = response.json()
                    st.json(health_data)
                except:
                    pass
            else:
                st.error("API server is not responding")
                st.info("Start the server with: `pipenv run python -m app.main`")
        
        with col2:
            st.subheader("Configuration")
            try:
                from app.config import get_settings
                settings = get_settings()
                config_info = {
                    "API URL": API_URL,
                    "Default Namespace": DEFAULT_NAMESPACE,
                    "Embedding Model": settings.embedding_model,
                    "LLM Model": settings.llm_model,
                    "Top K": settings.default_top_k,
                    "Supported Formats": ["PDF", "DOCX", "CSV"]
                }
            except:
                config_info = {
                    "API URL": API_URL,
                    "Default Namespace": DEFAULT_NAMESPACE,
                    "Supported Formats": ["PDF", "DOCX", "CSV"]
                }
            st.json(config_info)
        
        st.subheader("Usage Instructions")
        st.markdown("""
        1. **Upload Documents**: Go to the "Upload Documents" tab and upload your PDF, DOCX, or CSV files
        2. **Query Documents**: Go to the "Query Documents" tab and ask questions about your uploaded documents
        3. **Filter Results**: Use the source type filter to search specific document types (PDF, DOCX, CSV)
        4. **View Sources**: Expand source citations to see where the answer came from
        5. **Evaluation Results**: View the latest evaluation report in the "Evaluation Results" tab
        """)


if __name__ == "__main__":
    main()

